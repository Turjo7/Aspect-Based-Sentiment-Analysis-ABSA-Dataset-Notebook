{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6Np3k6mbZWF"
      },
      "source": [
        "**Checking Which Class Type has how Many Aspects**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "J4W8BawXbgc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9b7198c-b319-4db5-bbe4-5930afd0ce2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   class  id                                               text  text_length  \\\n",
            "0      0   1  thats true freedom speech doomed harassment su...           92   \n",
            "1      0   2               neener neener time go playground yet           36   \n",
            "2      0   3  like plastic gun fear armour piercing bullet f...           83   \n",
            "3      0   4          geology religion werent see rock x formed           41   \n",
            "4      0   5  well done monty mark first ever honest accurat...           52   \n",
            "\n",
            "   words_per_sentence  sentiment  polarity  subjectivity  \\\n",
            "0                  13   0.350000  0.350000      0.650000   \n",
            "1                   6   0.000000  0.000000      0.000000   \n",
            "2                  13   0.000000  0.000000      0.000000   \n",
            "3                   7   0.000000  0.000000      0.000000   \n",
            "4                   9   0.416667  0.416667      0.622222   \n",
            "\n",
            "                    aspects  \n",
            "0                        []  \n",
            "1  ['neener', 'playground']  \n",
            "2                ['armour']  \n",
            "3                  ['rock']  \n",
            "4                  ['post']  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/final_withaspects.csv')\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo3vKUgRb-lt",
        "outputId": "e066f3d9-153d-446f-d02b-9cdfdd7fa751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes with aspects:\n",
            "class\n",
            "1    2371\n",
            "0    1822\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Classes without aspects:\n",
            "class\n",
            "0    2871\n",
            "1    2322\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Function to convert aspect strings to lists\n",
        "import ast\n",
        "def convert_aspects(aspect_string):\n",
        "    if aspect_string == '[]':\n",
        "        return []\n",
        "    else:\n",
        "        return ast.literal_eval(aspect_string)\n",
        "\n",
        "# Apply the conversion function to the aspects column\n",
        "df['aspects'] = df['aspects'].apply(convert_aspects)\n",
        "\n",
        "# Analyze the classes\n",
        "class_with_aspects = df[df['aspects'].apply(lambda x: len(x) > 0)]['class'].value_counts()\n",
        "class_without_aspects = df[df['aspects'].apply(lambda x: len(x) == 0)]['class'].value_counts()\n",
        "\n",
        "# Print the results\n",
        "print(\"Classes with aspects:\")\n",
        "print(class_with_aspects)\n",
        "\n",
        "print(\"\\nClasses without aspects:\")\n",
        "print(class_without_aspects)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBVdNDSXiOqW",
        "outputId": "8f927917-eabb-4956-acf5-6d90f04ea97e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "class                   int64\n",
              "id                      int64\n",
              "text                   object\n",
              "text_length             int64\n",
              "words_per_sentence      int64\n",
              "sentiment             float64\n",
              "polarity              float64\n",
              "subjectivity          float64\n",
              "aspects                object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure there are no missing values in 'text' and 'aspect' columns\n",
        "df = df.dropna(subset=['text', 'aspects'])\n",
        "\n",
        "# Convert to string type\n",
        "df['text'] = df['text'].astype(str)\n",
        "df['aspects'] = df['aspects'].astype(str)"
      ],
      "metadata": {
        "id": "K4TbKSIH6BDK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "SxbEyp6-6d6k",
        "outputId": "8311c01a-87d0-49e4-c9db-4d6abd6fa4d2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      class    id                                               text  \\\n",
              "0         0     1  thats true freedom speech doomed harassment su...   \n",
              "1         0     2               neener neener time go playground yet   \n",
              "2         0     3  like plastic gun fear armour piercing bullet f...   \n",
              "3         0     4          geology religion werent see rock x formed   \n",
              "4         0     5  well done monty mark first ever honest accurat...   \n",
              "...     ...   ...                                                ...   \n",
              "9381      1  1698  tell genius accurately correctly pointing mist...   \n",
              "9382      1  1699  think good idea public school assume role pare...   \n",
              "9383      1  1700  settle charlie try think rationally second eve...   \n",
              "9384      1  1701  vpc ha political agenda fbi like saying believ...   \n",
              "9385      1  1702  didnt note explicitly put jesus said first two...   \n",
              "\n",
              "      text_length  words_per_sentence  sentiment  polarity  subjectivity  \\\n",
              "0              92                  13   0.350000  0.350000      0.650000   \n",
              "1              36                   6   0.000000  0.000000      0.000000   \n",
              "2              83                  13   0.000000  0.000000      0.000000   \n",
              "3              41                   7   0.000000  0.000000      0.000000   \n",
              "4              52                   9   0.416667  0.416667      0.622222   \n",
              "...           ...                 ...        ...       ...           ...   \n",
              "9381          195                  24   0.050000  0.050000      0.566667   \n",
              "9382          446                  62   0.068636  0.068636      0.373788   \n",
              "9383          180                  26   0.000000  0.000000      0.000000   \n",
              "9384           92                  15   0.250000  0.250000      0.300000   \n",
              "9385           84                  15   0.125000  0.125000      0.166667   \n",
              "\n",
              "                       aspects  \n",
              "0                           []  \n",
              "1     ['neener', 'playground']  \n",
              "2                   ['armour']  \n",
              "3                     ['rock']  \n",
              "4                     ['post']  \n",
              "...                        ...  \n",
              "9381                        []  \n",
              "9382         ['administrator']  \n",
              "9383               ['charlie']  \n",
              "9384                  ['coke']  \n",
              "9385                 ['jesus']  \n",
              "\n",
              "[9386 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-783c65a8-6772-497e-9109-931f491d8e9e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>text_length</th>\n",
              "      <th>words_per_sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>polarity</th>\n",
              "      <th>subjectivity</th>\n",
              "      <th>aspects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>thats true freedom speech doomed harassment su...</td>\n",
              "      <td>92</td>\n",
              "      <td>13</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>neener neener time go playground yet</td>\n",
              "      <td>36</td>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>['neener', 'playground']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>like plastic gun fear armour piercing bullet f...</td>\n",
              "      <td>83</td>\n",
              "      <td>13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>['armour']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>geology religion werent see rock x formed</td>\n",
              "      <td>41</td>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>['rock']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>well done monty mark first ever honest accurat...</td>\n",
              "      <td>52</td>\n",
              "      <td>9</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.622222</td>\n",
              "      <td>['post']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9381</th>\n",
              "      <td>1</td>\n",
              "      <td>1698</td>\n",
              "      <td>tell genius accurately correctly pointing mist...</td>\n",
              "      <td>195</td>\n",
              "      <td>24</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.566667</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9382</th>\n",
              "      <td>1</td>\n",
              "      <td>1699</td>\n",
              "      <td>think good idea public school assume role pare...</td>\n",
              "      <td>446</td>\n",
              "      <td>62</td>\n",
              "      <td>0.068636</td>\n",
              "      <td>0.068636</td>\n",
              "      <td>0.373788</td>\n",
              "      <td>['administrator']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9383</th>\n",
              "      <td>1</td>\n",
              "      <td>1700</td>\n",
              "      <td>settle charlie try think rationally second eve...</td>\n",
              "      <td>180</td>\n",
              "      <td>26</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>['charlie']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9384</th>\n",
              "      <td>1</td>\n",
              "      <td>1701</td>\n",
              "      <td>vpc ha political agenda fbi like saying believ...</td>\n",
              "      <td>92</td>\n",
              "      <td>15</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>['coke']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9385</th>\n",
              "      <td>1</td>\n",
              "      <td>1702</td>\n",
              "      <td>didnt note explicitly put jesus said first two...</td>\n",
              "      <td>84</td>\n",
              "      <td>15</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>['jesus']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9386 rows Ã— 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-783c65a8-6772-497e-9109-931f491d8e9e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-783c65a8-6772-497e-9109-931f491d8e9e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-783c65a8-6772-497e-9109-931f491d8e9e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d4f0e4dc-6e13-4304-ad54-170b80e68edf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d4f0e4dc-6e13-4304-ad54-170b80e68edf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d4f0e4dc-6e13-4304-ad54-170b80e68edf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6708f85e-979f-43e4-bbb7-c4262cbc42e7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6708f85e-979f-43e4-bbb7-c4262cbc42e7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 9386,\n  \"fields\": [\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1967,\n        \"min\": 1,\n        \"max\": 6520,\n        \"num_unique_values\": 6520,\n        \"samples\": [\n          5574,\n          2922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9075,\n        \"samples\": [\n          \"antichoicers control power woman dont care life except ownthis mother could person didnt access prenatal care wouldnt defend right eitherbecause dont care fetus dont care life dont care health care power money pushing people around thats\",\n          \"believe merely known living specie known fossil record extinct undoubtedly extinct specie unaware living one\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 122,\n        \"min\": 8,\n        \"max\": 697,\n        \"num_unique_values\": 568,\n        \"samples\": [\n          29,\n          129\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"words_per_sentence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 2,\n        \"max\": 109,\n        \"num_unique_values\": 90,\n        \"samples\": [\n          38,\n          24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2331170751648942,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2328,\n        \"samples\": [\n          0.026410256,\n          0.266666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"polarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2331170751648942,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2328,\n        \"samples\": [\n          0.026410256,\n          0.266666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subjectivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24785709461762806,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2439,\n        \"samples\": [\n          0.497619048,\n          0.33125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aspects\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1951,\n        \"samples\": [\n          \"['ally']\",\n          \"['caliber']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenization and input formatting\n",
        "def preprocess_data(texts, aspects, tokenizer, max_len=128):\n",
        "    input_ids, attention_masks = [], []\n",
        "\n",
        "    for text, aspect in zip(texts, aspects):\n",
        "        encoded = tokenizer.encode_plus(\n",
        "            text,\n",
        "            aspect,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        input_ids.append(encoded['input_ids'])\n",
        "        attention_masks.append(encoded['attention_mask'])\n",
        "\n",
        "    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0)\n",
        "\n",
        "# Assuming 'text', 'aspect', and 'sentiment' columns in the dataframe\n",
        "texts = df['text'].values\n",
        "aspects = df['aspects'].values\n",
        "labels = df['class'].values\n",
        "\n",
        "# Split the data\n",
        "train_texts, val_texts, train_aspects, val_aspects, train_labels, val_labels = train_test_split(texts, aspects, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "train_input_ids, train_attention_masks = preprocess_data(train_texts, train_aspects, tokenizer)\n",
        "val_input_ids, val_attention_masks = preprocess_data(val_texts, val_aspects, tokenizer)\n",
        "\n",
        "train_labels = torch.tensor(train_labels, dtype=torch.float32)\n",
        "val_labels = torch.tensor(val_labels, dtype=torch.float32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX8aR55L6hhi",
        "outputId": "8a7ceb9a-b4dc-4c93-ea23-f1744333c62e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
        "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
        "val_dataloader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "FBnIcxm-6rjT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "class BERT_RNN(nn.Module):\n",
        "    def __init__(self, bert, hidden_dim=128, output_dim=1, n_layers=1, bidirectional=True):\n",
        "        super(BERT_RNN, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.rnn = nn.LSTM(bert.config.hidden_size, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        cls_output = outputs[0]  # BERT's output\n",
        "\n",
        "        rnn_output, _ = self.rnn(cls_output)\n",
        "        final_output = self.fc(rnn_output[:, -1, :])\n",
        "        return self.sigmoid(final_output)\n",
        "\n",
        "# Load pre-trained BERT\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "model = BERT_RNN(bert)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpCN__og6u6C",
        "outputId": "a65382be-bb8e-4041-a8b2-c4e797209b09"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERT_RNN(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (rnn): LSTM(768, 128, batch_first=True, bidirectional=True)\n",
              "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
        "\n",
        "def train(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        b_input_ids, b_attention_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(b_input_ids, b_attention_mask)\n",
        "        loss = criterion(outputs.view(-1), b_labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            b_input_ids, b_attention_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            outputs = model(b_input_ids, b_attention_mask)\n",
        "            loss = criterion(outputs.view(-1), b_labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            all_preds.append(outputs.cpu().numpy())\n",
        "            all_labels.append(b_labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    all_preds = np.concatenate(all_preds, axis=0)\n",
        "    all_labels = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "    return avg_loss, all_preds, all_labels\n"
      ],
      "metadata": {
        "id": "M_uFDBc1601y"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train(model, train_dataloader, criterion, optimizer, device)\n",
        "    print(f'Epoch {epoch+1}, Train Loss: {train_loss}')\n"
      ],
      "metadata": {
        "id": "xV8aGJ5Z64mC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6bd0fa0-75ad-466b-c4b2-b2dd8c8f2bac"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train Loss: 0.573321167078424\n",
            "Epoch 2, Train Loss: 0.4417736361635492\n",
            "Epoch 3, Train Loss: 0.28004726813511643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = 'bert_rnn_model.pth'\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSZxUl1TarKD",
        "outputId": "a064a55f-8f1f-41f4-d7cb-48302c1eb780"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to bert_rnn_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "\n",
        "# Evaluate the Model and Compute Metrics\n",
        "val_loss, val_preds, val_labels = evaluate(model, val_dataloader, criterion, device)\n",
        "\n",
        "def compute_metrics(preds, labels):\n",
        "    pred_flat = np.round(preds).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    accuracy = accuracy_score(labels_flat, pred_flat)\n",
        "    precision = precision_score(labels_flat, pred_flat)\n",
        "    recall = recall_score(labels_flat, pred_flat)\n",
        "    f1 = f1_score(labels_flat, pred_flat)\n",
        "    roc_auc = roc_auc_score(labels_flat, preds)\n",
        "    conf_matrix = confusion_matrix(labels_flat, pred_flat)\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'roc_auc': roc_auc,\n",
        "        'conf_matrix': conf_matrix\n",
        "    }\n",
        "\n",
        "metrics = compute_metrics(val_preds, val_labels)\n",
        "\n",
        "print(f\"Validation Loss: {val_loss}\")\n",
        "print(f\"Accuracy: {metrics['accuracy']}\")\n",
        "print(f\"Precision: {metrics['precision']}\")\n",
        "print(f\"Recall: {metrics['recall']}\")\n",
        "print(f\"F1 Score: {metrics['f1']}\")\n",
        "print(f\"ROC AUC: {metrics['roc_auc']}\")\n",
        "print(f\"Confusion Matrix:\\n {metrics['conf_matrix']}\")"
      ],
      "metadata": {
        "id": "mpV_TS3gO-gb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ac474b8-fb0f-4990-f3ff-6eed14bc681c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.6105527928320028\n",
            "Accuracy: 0.7438764643237487\n",
            "Precision: 0.7931034482758621\n",
            "Recall: 0.6606382978723404\n",
            "F1 Score: 0.7208357515960535\n",
            "ROC AUC: 0.8289559043687339\n",
            "Confusion Matrix:\n",
            " [[776 162]\n",
            " [319 621]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}